{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import missingno as msno\n",
    "import seaborn as sns\n",
    "import pandas_profiling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv('Dataset/train.csv')\n",
    "soln_df = pd.read_csv('Dataset/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.drop(['pet_id'], axis = 1, inplace = True)\n",
    "main_test = soln_df.drop(['pet_id'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pre_process(df):\n",
    "    df.condition.fillna(3, inplace=True)\n",
    "    df['time_to_shelter'] = (pd.to_datetime(df.listing_date) - pd.to_datetime(df.issue_date)).dt.days\n",
    "    df.drop(['issue_date','listing_date'], axis = 1, inplace=True)\n",
    "    \n",
    "    top_colors = [\n",
    "                     'Black',\n",
    "                     'White',\n",
    "                     'Brown',\n",
    "                     'Brown Tabby',\n",
    "                     'Tan',\n",
    "                     'Blue',\n",
    "                     'Orange Tabby',\n",
    "                     'Red',\n",
    "                     'Brown Brindle',\n",
    "                     'Tricolor',\n",
    "                     'Blue Tabby',\n",
    "                     'Tortie',\n",
    "                     'Calico',\n",
    "                     'Gray',\n",
    "                     'Chocolate',\n",
    "                     'Torbie',\n",
    "                     'Cream Tabby',\n",
    "                     'Sable',\n",
    "                     'Cream',\n",
    "                     'Fawn',\n",
    "                     'Yellow',\n",
    "                     'Buff',\n",
    "                     'Lynx Point',\n",
    "                     'Blue Merle'\n",
    "                ]\n",
    "    \n",
    "    def reduce_color(color):\n",
    "        if color in top_colors:\n",
    "            return color\n",
    "        return 'Other'\n",
    "    \n",
    "    df['color_mod'] = df.color_type.apply(reduce_color)\n",
    "    df.drop(['color_type'], axis = 1, inplace=True)\n",
    "    df.drop(['length(m)','height(cm)'], axis = 1, inplace= True)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pre_process(train_df)\n",
    "main_test = pre_process(main_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_y1 = train_df.loc[:,['breed_category']]\n",
    "train_y2 = train_df.loc[:,['pet_category']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = train_df.drop(['breed_category','pet_category'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ColumnTransformer(n_jobs=None, remainder='passthrough', sparse_threshold=0.3,\n",
       "                  transformer_weights=None,\n",
       "                  transformers=[('color',\n",
       "                                 OneHotEncoder(categories='auto', drop='first',\n",
       "                                               dtype=<class 'numpy.float64'>,\n",
       "                                               handle_unknown='error',\n",
       "                                               sparse=False),\n",
       "                                 [4])],\n",
       "                  verbose=False)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ct = ColumnTransformer([(\"color\", OneHotEncoder(sparse=False, drop='first'), [4])], remainder = 'passthrough')\n",
    "ct.fit(train_X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_X = ct.transform(train_X)\n",
    "main_test = ct.transform(main_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(18834, 28)\n",
      "(8072, 28)\n"
     ]
    }
   ],
   "source": [
    "print(train_X.shape)\n",
    "print(main_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_breed, X_test_breed, y_train_breed, y_test_breed = train_test_split(train_X, train_y1, test_size = 0.2)\n",
    "X_train_pet, X_test_pet, y_train_pet, y_test_pet = train_test_split(train_X, train_y2, test_size = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "\n",
    "os = RandomOverSampler()\n",
    "\n",
    "X_train_breed, y_train_breed = os.fit_resample(X_train_breed, y_train_breed)\n",
    "X_train_pet, y_train_pet = os.fit_resample(X_train_pet, y_train_pet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.utils import np_utils\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.pipeline import Pipeline\n",
    "from keras.layers import Dropout\n",
    "from sklearn.metrics import confusion_matrix "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21702, 28)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_breed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21702, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_breed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def breed_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(15, input_dim=28, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(15,  activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(15,  activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(3, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pet_model():\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Dense(20, input_dim=28, activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(20,  activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(20,  activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "21702/21702 [==============================] - 1s 32us/step - loss: 21.9511 - accuracy: 0.3641\n",
      "Epoch 2/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 1.6483 - accuracy: 0.3554\n",
      "Epoch 3/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 1.2424 - accuracy: 0.4107\n",
      "Epoch 4/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 1.1422 - accuracy: 0.4119\n",
      "Epoch 5/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 1.1108 - accuracy: 0.4174\n",
      "Epoch 6/500\n",
      "21702/21702 [==============================] - 0s 20us/step - loss: 1.0703 - accuracy: 0.4177\n",
      "Epoch 7/500\n",
      "21702/21702 [==============================] - 0s 20us/step - loss: 1.0590 - accuracy: 0.4234\n",
      "Epoch 8/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 1.0333 - accuracy: 0.4278\n",
      "Epoch 9/500\n",
      "21702/21702 [==============================] - 1s 24us/step - loss: 1.0322 - accuracy: 0.4309\n",
      "Epoch 10/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 1.0047 - accuracy: 0.4351\n",
      "Epoch 11/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.9993 - accuracy: 0.4370\n",
      "Epoch 12/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.9855 - accuracy: 0.4443\n",
      "Epoch 13/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.9769 - accuracy: 0.4417\n",
      "Epoch 14/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.9688 - accuracy: 0.4443\n",
      "Epoch 15/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.9656 - accuracy: 0.4476\n",
      "Epoch 16/500\n",
      "21702/21702 [==============================] - 0s 20us/step - loss: 0.9598 - accuracy: 0.4484\n",
      "Epoch 17/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.9588 - accuracy: 0.4522\n",
      "Epoch 18/500\n",
      "21702/21702 [==============================] - 1s 25us/step - loss: 0.9521 - accuracy: 0.4625\n",
      "Epoch 19/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.9305 - accuracy: 0.4959\n",
      "Epoch 20/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.8035 - accuracy: 0.5816\n",
      "Epoch 21/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.7240 - accuracy: 0.6262\n",
      "Epoch 22/500\n",
      "21702/21702 [==============================] - 0s 20us/step - loss: 0.7220 - accuracy: 0.6120\n",
      "Epoch 23/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.6557 - accuracy: 0.6705\n",
      "Epoch 24/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.6921 - accuracy: 0.6460\n",
      "Epoch 25/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.6851 - accuracy: 0.6070\n",
      "Epoch 26/500\n",
      "21702/21702 [==============================] - 0s 20us/step - loss: 0.6585 - accuracy: 0.6353\n",
      "Epoch 27/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.5959 - accuracy: 0.6917\n",
      "Epoch 28/500\n",
      "21702/21702 [==============================] - 1s 24us/step - loss: 0.5895 - accuracy: 0.7019\n",
      "Epoch 29/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.6650 - accuracy: 0.6476\n",
      "Epoch 30/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5956 - accuracy: 0.6948\n",
      "Epoch 31/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.5525 - accuracy: 0.7091\n",
      "Epoch 32/500\n",
      "21702/21702 [==============================] - 0s 20us/step - loss: 0.5585 - accuracy: 0.7199\n",
      "Epoch 33/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.6314 - accuracy: 0.7005\n",
      "Epoch 34/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.5384 - accuracy: 0.7263\n",
      "Epoch 35/500\n",
      "21702/21702 [==============================] - 1s 25us/step - loss: 0.5359 - accuracy: 0.7330\n",
      "Epoch 36/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.5292 - accuracy: 0.7365\n",
      "Epoch 37/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.5001 - accuracy: 0.7665\n",
      "Epoch 38/500\n",
      "21702/21702 [==============================] - 1s 24us/step - loss: 0.5843 - accuracy: 0.7121\n",
      "Epoch 39/500\n",
      "21702/21702 [==============================] - 1s 25us/step - loss: 0.4805 - accuracy: 0.7686\n",
      "Epoch 40/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4497 - accuracy: 0.7860\n",
      "Epoch 41/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4635 - accuracy: 0.7787\n",
      "Epoch 42/500\n",
      "21702/21702 [==============================] - 1s 24us/step - loss: 0.5346 - accuracy: 0.7541\n",
      "Epoch 43/500\n",
      "21702/21702 [==============================] - 1s 25us/step - loss: 0.4566 - accuracy: 0.7737\n",
      "Epoch 44/500\n",
      "21702/21702 [==============================] - 1s 24us/step - loss: 0.4950 - accuracy: 0.7662\n",
      "Epoch 45/500\n",
      "21702/21702 [==============================] - 1s 24us/step - loss: 0.5330 - accuracy: 0.7633\n",
      "Epoch 46/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4822 - accuracy: 0.7903\n",
      "Epoch 47/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.5949 - accuracy: 0.7202\n",
      "Epoch 48/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4927 - accuracy: 0.7954\n",
      "Epoch 49/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.5720 - accuracy: 0.7643\n",
      "Epoch 50/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.5748 - accuracy: 0.7417\n",
      "Epoch 51/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.5902 - accuracy: 0.7369\n",
      "Epoch 52/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.5472 - accuracy: 0.7229\n",
      "Epoch 53/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.5609 - accuracy: 0.7402\n",
      "Epoch 54/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4433 - accuracy: 0.8070\n",
      "Epoch 55/500\n",
      "21702/21702 [==============================] - 0s 20us/step - loss: 0.4094 - accuracy: 0.8264\n",
      "Epoch 56/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.3860 - accuracy: 0.8282\n",
      "Epoch 57/500\n",
      "21702/21702 [==============================] - 1s 25us/step - loss: 0.4619 - accuracy: 0.8126\n",
      "Epoch 58/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4462 - accuracy: 0.8225\n",
      "Epoch 59/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4323 - accuracy: 0.8296\n",
      "Epoch 60/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4637 - accuracy: 0.8042\n",
      "Epoch 61/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4464 - accuracy: 0.8317\n",
      "Epoch 62/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4594 - accuracy: 0.8144\n",
      "Epoch 63/500\n",
      "21702/21702 [==============================] - 1s 24us/step - loss: 0.4773 - accuracy: 0.8107\n",
      "Epoch 64/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4283 - accuracy: 0.8255\n",
      "Epoch 65/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4222 - accuracy: 0.8252\n",
      "Epoch 66/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4613 - accuracy: 0.8210\n",
      "Epoch 67/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.5196 - accuracy: 0.7879\n",
      "Epoch 68/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4986 - accuracy: 0.7864\n",
      "Epoch 69/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.5242 - accuracy: 0.7916\n",
      "Epoch 70/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.5042 - accuracy: 0.8049\n",
      "Epoch 71/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4356 - accuracy: 0.8254\n",
      "Epoch 72/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4616 - accuracy: 0.8237\n",
      "Epoch 73/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.3947 - accuracy: 0.8464\n",
      "Epoch 74/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4276 - accuracy: 0.8320\n",
      "Epoch 75/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4365 - accuracy: 0.8298\n",
      "Epoch 76/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.5963 - accuracy: 0.7449\n",
      "Epoch 77/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5305 - accuracy: 0.7908\n",
      "Epoch 78/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.5665 - accuracy: 0.8097\n",
      "Epoch 79/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4737 - accuracy: 0.7966\n",
      "Epoch 80/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4580 - accuracy: 0.8197\n",
      "Epoch 81/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4789 - accuracy: 0.8088\n",
      "Epoch 82/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.5033 - accuracy: 0.8017\n",
      "Epoch 83/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.5255 - accuracy: 0.7949\n",
      "Epoch 84/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4205 - accuracy: 0.8304\n",
      "Epoch 85/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.3972 - accuracy: 0.8404\n",
      "Epoch 86/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4854 - accuracy: 0.8108\n",
      "Epoch 87/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4795 - accuracy: 0.7913\n",
      "Epoch 88/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4618 - accuracy: 0.8214\n",
      "Epoch 89/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4350 - accuracy: 0.8263\n",
      "Epoch 90/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4429 - accuracy: 0.8207\n",
      "Epoch 91/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.5506 - accuracy: 0.7810\n",
      "Epoch 92/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4248 - accuracy: 0.8229\n",
      "Epoch 93/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4638 - accuracy: 0.8202\n",
      "Epoch 94/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.5072 - accuracy: 0.8064\n",
      "Epoch 95/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4815 - accuracy: 0.8010\n",
      "Epoch 96/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4871 - accuracy: 0.7974\n",
      "Epoch 97/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.5539 - accuracy: 0.7650\n",
      "Epoch 98/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4864 - accuracy: 0.7890\n",
      "Epoch 99/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4940 - accuracy: 0.7993\n",
      "Epoch 100/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.5294 - accuracy: 0.8048\n",
      "Epoch 101/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4236 - accuracy: 0.8296\n",
      "Epoch 102/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4193 - accuracy: 0.8284\n",
      "Epoch 103/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4668 - accuracy: 0.8095\n",
      "Epoch 104/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4510 - accuracy: 0.8139\n",
      "Epoch 105/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4142 - accuracy: 0.8135\n",
      "Epoch 106/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4308 - accuracy: 0.8125\n",
      "Epoch 107/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4809 - accuracy: 0.8119\n",
      "Epoch 108/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.3605 - accuracy: 0.8306\n",
      "Epoch 109/500\n",
      "21702/21702 [==============================] - 1s 24us/step - loss: 0.4297 - accuracy: 0.8223\n",
      "Epoch 110/500\n",
      "21702/21702 [==============================] - 1s 24us/step - loss: 0.3689 - accuracy: 0.8336\n",
      "Epoch 111/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.4090 - accuracy: 0.7998\n",
      "Epoch 112/500\n",
      "21702/21702 [==============================] - 1s 23us/step - loss: 0.4186 - accuracy: 0.8256\n",
      "Epoch 113/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4436 - accuracy: 0.7998\n",
      "Epoch 114/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4547 - accuracy: 0.8065\n",
      "Epoch 115/500\n",
      "21702/21702 [==============================] - 1s 24us/step - loss: 0.3984 - accuracy: 0.8302\n",
      "Epoch 116/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4820 - accuracy: 0.8066\n",
      "Epoch 117/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3180 - accuracy: 0.8541\n",
      "Epoch 118/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4391 - accuracy: 0.7818\n",
      "Epoch 119/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5568 - accuracy: 0.7479\n",
      "Epoch 120/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4102 - accuracy: 0.8328\n",
      "Epoch 121/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.4395 - accuracy: 0.8229\n",
      "Epoch 122/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.4779 - accuracy: 0.7937\n",
      "Epoch 123/500\n",
      "21702/21702 [==============================] - 1s 26us/step - loss: 0.4400 - accuracy: 0.8150\n",
      "Epoch 124/500\n",
      "21702/21702 [==============================] - 1s 25us/step - loss: 0.4079 - accuracy: 0.8416\n",
      "Epoch 125/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3547 - accuracy: 0.8477\n",
      "Epoch 126/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.4605 - accuracy: 0.7966\n",
      "Epoch 127/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4295 - accuracy: 0.8199\n",
      "Epoch 128/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3568 - accuracy: 0.8427\n",
      "Epoch 129/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4655 - accuracy: 0.8085\n",
      "Epoch 130/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5349 - accuracy: 0.7541\n",
      "Epoch 131/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4604 - accuracy: 0.7944\n",
      "Epoch 132/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3491 - accuracy: 0.8280\n",
      "Epoch 133/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3896 - accuracy: 0.8089\n",
      "Epoch 134/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5147 - accuracy: 0.7993\n",
      "Epoch 135/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3820 - accuracy: 0.8144\n",
      "Epoch 136/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3902 - accuracy: 0.8139\n",
      "Epoch 137/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3593 - accuracy: 0.8319\n",
      "Epoch 138/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4966 - accuracy: 0.7694\n",
      "Epoch 139/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5276 - accuracy: 0.7396\n",
      "Epoch 140/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4829 - accuracy: 0.7675\n",
      "Epoch 141/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.3819 - accuracy: 0.8283\n",
      "Epoch 142/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4033 - accuracy: 0.8034\n",
      "Epoch 143/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4664 - accuracy: 0.7719\n",
      "Epoch 144/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5379 - accuracy: 0.7739\n",
      "Epoch 145/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3839 - accuracy: 0.8290\n",
      "Epoch 146/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4373 - accuracy: 0.7985\n",
      "Epoch 147/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3658 - accuracy: 0.8336\n",
      "Epoch 148/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3890 - accuracy: 0.8359\n",
      "Epoch 149/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3864 - accuracy: 0.8284\n",
      "Epoch 150/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4247 - accuracy: 0.8005\n",
      "Epoch 151/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4159 - accuracy: 0.8179\n",
      "Epoch 152/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4548 - accuracy: 0.8041\n",
      "Epoch 153/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4564 - accuracy: 0.8067\n",
      "Epoch 154/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4189 - accuracy: 0.8193\n",
      "Epoch 155/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4633 - accuracy: 0.8109\n",
      "Epoch 156/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5279 - accuracy: 0.7791\n",
      "Epoch 157/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5158 - accuracy: 0.7891\n",
      "Epoch 158/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4444 - accuracy: 0.8170\n",
      "Epoch 159/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4251 - accuracy: 0.8038\n",
      "Epoch 160/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3336 - accuracy: 0.8488\n",
      "Epoch 161/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4332 - accuracy: 0.8112\n",
      "Epoch 162/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4203 - accuracy: 0.7957\n",
      "Epoch 163/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4157 - accuracy: 0.7945\n",
      "Epoch 164/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3918 - accuracy: 0.8215\n",
      "Epoch 165/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3526 - accuracy: 0.8330\n",
      "Epoch 166/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4746 - accuracy: 0.7967\n",
      "Epoch 167/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3507 - accuracy: 0.8359\n",
      "Epoch 168/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3328 - accuracy: 0.8473\n",
      "Epoch 169/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3254 - accuracy: 0.8514\n",
      "Epoch 170/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3562 - accuracy: 0.8415\n",
      "Epoch 171/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2934 - accuracy: 0.8602\n",
      "Epoch 172/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3070 - accuracy: 0.8498\n",
      "Epoch 173/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3602 - accuracy: 0.8466\n",
      "Epoch 174/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3290 - accuracy: 0.8511\n",
      "Epoch 175/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2947 - accuracy: 0.8538\n",
      "Epoch 176/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3169 - accuracy: 0.8540\n",
      "Epoch 177/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3705 - accuracy: 0.8218\n",
      "Epoch 178/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4336 - accuracy: 0.7957\n",
      "Epoch 179/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3751 - accuracy: 0.8188\n",
      "Epoch 180/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4983 - accuracy: 0.7596\n",
      "Epoch 181/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4385 - accuracy: 0.7852\n",
      "Epoch 182/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3607 - accuracy: 0.8290\n",
      "Epoch 183/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4123 - accuracy: 0.8420\n",
      "Epoch 184/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3375 - accuracy: 0.8488\n",
      "Epoch 185/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3142 - accuracy: 0.8685\n",
      "Epoch 186/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3253 - accuracy: 0.8589\n",
      "Epoch 187/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2986 - accuracy: 0.8557\n",
      "Epoch 188/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2802 - accuracy: 0.8606\n",
      "Epoch 189/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3168 - accuracy: 0.8531\n",
      "Epoch 190/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2699 - accuracy: 0.8759\n",
      "Epoch 191/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2958 - accuracy: 0.8555\n",
      "Epoch 192/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3997 - accuracy: 0.8162\n",
      "Epoch 193/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2976 - accuracy: 0.8614\n",
      "Epoch 194/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2658 - accuracy: 0.8668\n",
      "Epoch 195/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2922 - accuracy: 0.8596\n",
      "Epoch 196/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2648 - accuracy: 0.8652\n",
      "Epoch 197/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3651 - accuracy: 0.8226\n",
      "Epoch 198/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3891 - accuracy: 0.8300\n",
      "Epoch 199/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2584 - accuracy: 0.8795\n",
      "Epoch 200/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3317 - accuracy: 0.8331\n",
      "Epoch 201/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3545 - accuracy: 0.8353\n",
      "Epoch 202/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2931 - accuracy: 0.8490\n",
      "Epoch 203/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2838 - accuracy: 0.8533\n",
      "Epoch 204/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3745 - accuracy: 0.8121\n",
      "Epoch 205/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3333 - accuracy: 0.8303\n",
      "Epoch 206/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3481 - accuracy: 0.8315\n",
      "Epoch 207/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3637 - accuracy: 0.8261\n",
      "Epoch 208/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4986 - accuracy: 0.7665\n",
      "Epoch 209/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5193 - accuracy: 0.7463\n",
      "Epoch 210/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5130 - accuracy: 0.7568\n",
      "Epoch 211/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4061 - accuracy: 0.8132\n",
      "Epoch 212/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3932 - accuracy: 0.8097\n",
      "Epoch 213/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4383 - accuracy: 0.7895\n",
      "Epoch 214/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4085 - accuracy: 0.8091\n",
      "Epoch 215/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3396 - accuracy: 0.8360\n",
      "Epoch 216/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3078 - accuracy: 0.8373\n",
      "Epoch 217/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3601 - accuracy: 0.8220\n",
      "Epoch 218/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4259 - accuracy: 0.8142\n",
      "Epoch 219/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3485 - accuracy: 0.8331\n",
      "Epoch 220/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3571 - accuracy: 0.8179\n",
      "Epoch 221/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3886 - accuracy: 0.8134\n",
      "Epoch 222/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3842 - accuracy: 0.8131\n",
      "Epoch 223/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3934 - accuracy: 0.7968\n",
      "Epoch 224/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3175 - accuracy: 0.8388\n",
      "Epoch 225/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3618 - accuracy: 0.8173\n",
      "Epoch 226/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2937 - accuracy: 0.8479\n",
      "Epoch 227/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3345 - accuracy: 0.8277\n",
      "Epoch 228/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4844 - accuracy: 0.7751\n",
      "Epoch 229/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5011 - accuracy: 0.7415\n",
      "Epoch 230/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4817 - accuracy: 0.7603\n",
      "Epoch 231/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4745 - accuracy: 0.7682\n",
      "Epoch 232/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3815 - accuracy: 0.8202\n",
      "Epoch 233/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3579 - accuracy: 0.8367\n",
      "Epoch 234/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3617 - accuracy: 0.8315\n",
      "Epoch 235/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3895 - accuracy: 0.8139\n",
      "Epoch 236/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5703 - accuracy: 0.7830\n",
      "Epoch 237/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5122 - accuracy: 0.7646\n",
      "Epoch 238/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3420 - accuracy: 0.8414\n",
      "Epoch 239/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3658 - accuracy: 0.8302\n",
      "Epoch 240/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4204 - accuracy: 0.8034\n",
      "Epoch 241/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4524 - accuracy: 0.7852 0s - loss: 0.4835 - accuracy: \n",
      "Epoch 242/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3739 - accuracy: 0.8283\n",
      "Epoch 243/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4348 - accuracy: 0.7896\n",
      "Epoch 244/500\n",
      "21702/21702 [==============================] - 1s 23us/step - loss: 0.3518 - accuracy: 0.8338\n",
      "Epoch 245/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.4571 - accuracy: 0.7743\n",
      "Epoch 246/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3214 - accuracy: 0.8347\n",
      "Epoch 247/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.3410 - accuracy: 0.8366\n",
      "Epoch 248/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3970 - accuracy: 0.8044\n",
      "Epoch 249/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4464 - accuracy: 0.7760\n",
      "Epoch 250/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3760 - accuracy: 0.8197\n",
      "Epoch 251/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3405 - accuracy: 0.8357\n",
      "Epoch 252/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4179 - accuracy: 0.8177\n",
      "Epoch 253/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3445 - accuracy: 0.8364\n",
      "Epoch 254/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3647 - accuracy: 0.8320\n",
      "Epoch 255/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2761 - accuracy: 0.8618\n",
      "Epoch 256/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5520 - accuracy: 0.7170\n",
      "Epoch 257/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4714 - accuracy: 0.7602\n",
      "Epoch 258/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5251 - accuracy: 0.7485\n",
      "Epoch 259/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5119 - accuracy: 0.7512\n",
      "Epoch 260/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5063 - accuracy: 0.7505\n",
      "Epoch 261/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4062 - accuracy: 0.7970\n",
      "Epoch 262/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3546 - accuracy: 0.8344\n",
      "Epoch 263/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4717 - accuracy: 0.7861\n",
      "Epoch 264/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.6853 - accuracy: 0.6417\n",
      "Epoch 265/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.6779 - accuracy: 0.6451\n",
      "Epoch 266/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5914 - accuracy: 0.7252\n",
      "Epoch 267/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5026 - accuracy: 0.7648\n",
      "Epoch 268/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5930 - accuracy: 0.7511\n",
      "Epoch 269/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4467 - accuracy: 0.7934\n",
      "Epoch 270/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3880 - accuracy: 0.8400\n",
      "Epoch 271/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3705 - accuracy: 0.8472\n",
      "Epoch 272/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3643 - accuracy: 0.8113\n",
      "Epoch 273/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3566 - accuracy: 0.8223\n",
      "Epoch 274/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3507 - accuracy: 0.8279\n",
      "Epoch 275/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5481 - accuracy: 0.7756\n",
      "Epoch 276/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2935 - accuracy: 0.8417\n",
      "Epoch 277/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5159 - accuracy: 0.7734\n",
      "Epoch 278/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3791 - accuracy: 0.8147\n",
      "Epoch 279/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3621 - accuracy: 0.8188\n",
      "Epoch 280/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4346 - accuracy: 0.7902\n",
      "Epoch 281/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5244 - accuracy: 0.8049\n",
      "Epoch 282/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3790 - accuracy: 0.8303\n",
      "Epoch 283/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.3195 - accuracy: 0.8382\n",
      "Epoch 284/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2806 - accuracy: 0.8585\n",
      "Epoch 285/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2713 - accuracy: 0.8678\n",
      "Epoch 286/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.2636 - accuracy: 0.8716\n",
      "Epoch 287/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3563 - accuracy: 0.8366\n",
      "Epoch 288/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2546 - accuracy: 0.8739\n",
      "Epoch 289/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4037 - accuracy: 0.8296\n",
      "Epoch 290/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.7994 - accuracy: 0.6721\n",
      "Epoch 291/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.6772 - accuracy: 0.6683\n",
      "Epoch 292/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.6419 - accuracy: 0.6847\n",
      "Epoch 293/500\n",
      "21702/21702 [==============================] - 1s 23us/step - loss: 0.5698 - accuracy: 0.7113\n",
      "Epoch 294/500\n",
      "21702/21702 [==============================] - 1s 24us/step - loss: 0.4309 - accuracy: 0.8085\n",
      "Epoch 295/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.5624 - accuracy: 0.7601\n",
      "Epoch 296/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5341 - accuracy: 0.7845\n",
      "Epoch 297/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4042 - accuracy: 0.8202\n",
      "Epoch 298/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3919 - accuracy: 0.8194\n",
      "Epoch 299/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3638 - accuracy: 0.8271\n",
      "Epoch 300/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3276 - accuracy: 0.8560\n",
      "Epoch 301/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3004 - accuracy: 0.8520\n",
      "Epoch 302/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3266 - accuracy: 0.8470\n",
      "Epoch 303/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3652 - accuracy: 0.8294\n",
      "Epoch 304/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4384 - accuracy: 0.7916\n",
      "Epoch 305/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2858 - accuracy: 0.8536\n",
      "Epoch 306/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3321 - accuracy: 0.8545\n",
      "Epoch 307/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3761 - accuracy: 0.8344\n",
      "Epoch 308/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3909 - accuracy: 0.8317\n",
      "Epoch 309/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3531 - accuracy: 0.8463\n",
      "Epoch 310/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3333 - accuracy: 0.8382\n",
      "Epoch 311/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3617 - accuracy: 0.8238\n",
      "Epoch 312/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3189 - accuracy: 0.8368\n",
      "Epoch 313/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3488 - accuracy: 0.8284\n",
      "Epoch 314/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.3564 - accuracy: 0.8103\n",
      "Epoch 315/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3803 - accuracy: 0.8266\n",
      "Epoch 316/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3970 - accuracy: 0.8243\n",
      "Epoch 317/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5122 - accuracy: 0.7534\n",
      "Epoch 318/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4060 - accuracy: 0.8132\n",
      "Epoch 319/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5024 - accuracy: 0.7619\n",
      "Epoch 320/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5667 - accuracy: 0.7173\n",
      "Epoch 321/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5757 - accuracy: 0.7403 0s - loss: 0.5920 - accura\n",
      "Epoch 322/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4888 - accuracy: 0.7929\n",
      "Epoch 323/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4289 - accuracy: 0.8094\n",
      "Epoch 324/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4261 - accuracy: 0.8133\n",
      "Epoch 325/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4346 - accuracy: 0.8072\n",
      "Epoch 326/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3651 - accuracy: 0.8288\n",
      "Epoch 327/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.3302 - accuracy: 0.8322\n",
      "Epoch 328/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.4330 - accuracy: 0.7842\n",
      "Epoch 329/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3709 - accuracy: 0.8192\n",
      "Epoch 330/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4627 - accuracy: 0.7753\n",
      "Epoch 331/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.3937 - accuracy: 0.8117\n",
      "Epoch 332/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.3824 - accuracy: 0.8326\n",
      "Epoch 333/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4418 - accuracy: 0.7984\n",
      "Epoch 334/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3709 - accuracy: 0.8230\n",
      "Epoch 335/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3467 - accuracy: 0.8355\n",
      "Epoch 336/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.3880 - accuracy: 0.8255\n",
      "Epoch 337/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4145 - accuracy: 0.8260\n",
      "Epoch 338/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3065 - accuracy: 0.8429\n",
      "Epoch 339/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3185 - accuracy: 0.8435\n",
      "Epoch 340/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.3442 - accuracy: 0.8351\n",
      "Epoch 341/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3805 - accuracy: 0.8416\n",
      "Epoch 342/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5230 - accuracy: 0.7717\n",
      "Epoch 343/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4844 - accuracy: 0.7879\n",
      "Epoch 344/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4214 - accuracy: 0.8052\n",
      "Epoch 345/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3337 - accuracy: 0.8233\n",
      "Epoch 346/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3784 - accuracy: 0.8139\n",
      "Epoch 347/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3850 - accuracy: 0.8303\n",
      "Epoch 348/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.3676 - accuracy: 0.8221\n",
      "Epoch 349/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3494 - accuracy: 0.8180\n",
      "Epoch 350/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3721 - accuracy: 0.8218\n",
      "Epoch 351/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3264 - accuracy: 0.8425\n",
      "Epoch 352/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.3331 - accuracy: 0.8310\n",
      "Epoch 353/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3382 - accuracy: 0.8353\n",
      "Epoch 354/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3186 - accuracy: 0.8432\n",
      "Epoch 355/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3521 - accuracy: 0.8323\n",
      "Epoch 356/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2958 - accuracy: 0.8528\n",
      "Epoch 357/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3542 - accuracy: 0.8388\n",
      "Epoch 358/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4902 - accuracy: 0.7597\n",
      "Epoch 359/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5448 - accuracy: 0.7879\n",
      "Epoch 360/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3678 - accuracy: 0.8456\n",
      "Epoch 361/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4260 - accuracy: 0.8325\n",
      "Epoch 362/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3517 - accuracy: 0.8470\n",
      "Epoch 363/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3593 - accuracy: 0.8484\n",
      "Epoch 364/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4721 - accuracy: 0.8116\n",
      "Epoch 365/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4026 - accuracy: 0.8390\n",
      "Epoch 366/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3615 - accuracy: 0.8446\n",
      "Epoch 367/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3968 - accuracy: 0.8379\n",
      "Epoch 368/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3310 - accuracy: 0.8441\n",
      "Epoch 369/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.4927 - accuracy: 0.8056\n",
      "Epoch 370/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4793 - accuracy: 0.8128\n",
      "Epoch 371/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3922 - accuracy: 0.8353\n",
      "Epoch 372/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.3657 - accuracy: 0.8435\n",
      "Epoch 373/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.5039 - accuracy: 0.8034\n",
      "Epoch 374/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2994 - accuracy: 0.8595\n",
      "Epoch 375/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3546 - accuracy: 0.8488\n",
      "Epoch 376/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2998 - accuracy: 0.8544\n",
      "Epoch 377/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3119 - accuracy: 0.8595\n",
      "Epoch 378/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2971 - accuracy: 0.8585\n",
      "Epoch 379/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2598 - accuracy: 0.8699\n",
      "Epoch 380/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4455 - accuracy: 0.8078\n",
      "Epoch 381/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3625 - accuracy: 0.8510\n",
      "Epoch 382/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4468 - accuracy: 0.8276\n",
      "Epoch 383/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5126 - accuracy: 0.7981\n",
      "Epoch 384/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3527 - accuracy: 0.8611\n",
      "Epoch 385/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3015 - accuracy: 0.8625\n",
      "Epoch 386/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3801 - accuracy: 0.8316\n",
      "Epoch 387/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3913 - accuracy: 0.8379\n",
      "Epoch 388/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3066 - accuracy: 0.8596\n",
      "Epoch 389/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.3450 - accuracy: 0.8382\n",
      "Epoch 390/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.2815 - accuracy: 0.8535\n",
      "Epoch 391/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2846 - accuracy: 0.8609\n",
      "Epoch 392/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2955 - accuracy: 0.8490\n",
      "Epoch 393/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3269 - accuracy: 0.8420\n",
      "Epoch 394/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3599 - accuracy: 0.8564\n",
      "Epoch 395/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3738 - accuracy: 0.8469\n",
      "Epoch 396/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4114 - accuracy: 0.8323\n",
      "Epoch 397/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3013 - accuracy: 0.8679\n",
      "Epoch 398/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3466 - accuracy: 0.8582\n",
      "Epoch 399/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3820 - accuracy: 0.8451\n",
      "Epoch 400/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3981 - accuracy: 0.8320\n",
      "Epoch 401/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3086 - accuracy: 0.8573\n",
      "Epoch 402/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.3211 - accuracy: 0.8551\n",
      "Epoch 403/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3878 - accuracy: 0.8298\n",
      "Epoch 404/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2910 - accuracy: 0.8598\n",
      "Epoch 405/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2472 - accuracy: 0.8688\n",
      "Epoch 406/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2973 - accuracy: 0.8535\n",
      "Epoch 407/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.3000 - accuracy: 0.8561\n",
      "Epoch 408/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2696 - accuracy: 0.8638\n",
      "Epoch 409/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3790 - accuracy: 0.8570\n",
      "Epoch 410/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3520 - accuracy: 0.8540\n",
      "Epoch 411/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3440 - accuracy: 0.8620\n",
      "Epoch 412/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3416 - accuracy: 0.8546\n",
      "Epoch 413/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3084 - accuracy: 0.8608\n",
      "Epoch 414/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.3205 - accuracy: 0.8534\n",
      "Epoch 415/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3352 - accuracy: 0.8428\n",
      "Epoch 416/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2752 - accuracy: 0.8692\n",
      "Epoch 417/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3053 - accuracy: 0.8509\n",
      "Epoch 418/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3480 - accuracy: 0.8375\n",
      "Epoch 419/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2729 - accuracy: 0.8534\n",
      "Epoch 420/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3072 - accuracy: 0.8453\n",
      "Epoch 421/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3162 - accuracy: 0.8330\n",
      "Epoch 422/500\n",
      "21702/21702 [==============================] - 1s 23us/step - loss: 0.3023 - accuracy: 0.8339\n",
      "Epoch 423/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2808 - accuracy: 0.8378\n",
      "Epoch 424/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.2635 - accuracy: 0.8557\n",
      "Epoch 425/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3259 - accuracy: 0.8395\n",
      "Epoch 426/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.3254 - accuracy: 0.8400\n",
      "Epoch 427/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3479 - accuracy: 0.8421\n",
      "Epoch 428/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4044 - accuracy: 0.8296\n",
      "Epoch 429/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3246 - accuracy: 0.8350\n",
      "Epoch 430/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.2816 - accuracy: 0.8550\n",
      "Epoch 431/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3338 - accuracy: 0.8245\n",
      "Epoch 432/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2520 - accuracy: 0.8580\n",
      "Epoch 433/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.4611 - accuracy: 0.7728\n",
      "Epoch 434/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2645 - accuracy: 0.8737\n",
      "Epoch 435/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2600 - accuracy: 0.8797\n",
      "Epoch 436/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3032 - accuracy: 0.8541\n",
      "Epoch 437/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3254 - accuracy: 0.8455\n",
      "Epoch 438/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2341 - accuracy: 0.8825\n",
      "Epoch 439/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.2829 - accuracy: 0.8672\n",
      "Epoch 440/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2522 - accuracy: 0.8688\n",
      "Epoch 441/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2875 - accuracy: 0.8633\n",
      "Epoch 442/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2575 - accuracy: 0.8696\n",
      "Epoch 443/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.2954 - accuracy: 0.8623\n",
      "Epoch 444/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2683 - accuracy: 0.8663\n",
      "Epoch 445/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.5144 - accuracy: 0.7474\n",
      "Epoch 446/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3940 - accuracy: 0.8063\n",
      "Epoch 447/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4582 - accuracy: 0.7744\n",
      "Epoch 448/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3325 - accuracy: 0.8490\n",
      "Epoch 449/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.2520 - accuracy: 0.8774\n",
      "Epoch 450/500\n",
      "21702/21702 [==============================] - 0s 21us/step - loss: 0.2639 - accuracy: 0.8686\n",
      "Epoch 451/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.2691 - accuracy: 0.8628\n",
      "Epoch 452/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.3929 - accuracy: 0.8244\n",
      "Epoch 453/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.3711 - accuracy: 0.8437\n",
      "Epoch 454/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.3368 - accuracy: 0.8471\n",
      "Epoch 455/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4315 - accuracy: 0.8647\n",
      "Epoch 456/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2645 - accuracy: 0.8753\n",
      "Epoch 457/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2246 - accuracy: 0.8880\n",
      "Epoch 458/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2226 - accuracy: 0.8879\n",
      "Epoch 459/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3298 - accuracy: 0.8539\n",
      "Epoch 460/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3175 - accuracy: 0.8541\n",
      "Epoch 461/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2615 - accuracy: 0.8787\n",
      "Epoch 462/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2393 - accuracy: 0.8781\n",
      "Epoch 463/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2196 - accuracy: 0.8869\n",
      "Epoch 464/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.2190 - accuracy: 0.8760\n",
      "Epoch 465/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3928 - accuracy: 0.8222\n",
      "Epoch 466/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3331 - accuracy: 0.8361\n",
      "Epoch 467/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2591 - accuracy: 0.8807\n",
      "Epoch 468/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4094 - accuracy: 0.8357\n",
      "Epoch 469/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.4744 - accuracy: 0.7802\n",
      "Epoch 470/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.5068 - accuracy: 0.7258\n",
      "Epoch 471/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4906 - accuracy: 0.7369\n",
      "Epoch 472/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.4577 - accuracy: 0.7568 0s - loss: 0.4707 - accuracy\n",
      "Epoch 473/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4136 - accuracy: 0.7858\n",
      "Epoch 474/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.4323 - accuracy: 0.7911\n",
      "Epoch 475/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.4880 - accuracy: 0.7545\n",
      "Epoch 476/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.5111 - accuracy: 0.8088\n",
      "Epoch 477/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2510 - accuracy: 0.8647\n",
      "Epoch 478/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.2511 - accuracy: 0.8648\n",
      "Epoch 479/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2526 - accuracy: 0.8765\n",
      "Epoch 480/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3314 - accuracy: 0.8590\n",
      "Epoch 481/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3131 - accuracy: 0.8685\n",
      "Epoch 482/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.2163 - accuracy: 0.8830\n",
      "Epoch 483/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3080 - accuracy: 0.8539\n",
      "Epoch 484/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.2654 - accuracy: 0.8703\n",
      "Epoch 485/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.2417 - accuracy: 0.8784\n",
      "Epoch 486/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.2808 - accuracy: 0.8776\n",
      "Epoch 487/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.2352 - accuracy: 0.8875\n",
      "Epoch 488/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.2756 - accuracy: 0.8601\n",
      "Epoch 489/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.2585 - accuracy: 0.8757\n",
      "Epoch 490/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2148 - accuracy: 0.8838\n",
      "Epoch 491/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3374 - accuracy: 0.8320\n",
      "Epoch 492/500\n",
      "21702/21702 [==============================] - 1s 24us/step - loss: 0.4005 - accuracy: 0.8107\n",
      "Epoch 493/500\n",
      "21702/21702 [==============================] - 1s 23us/step - loss: 0.3776 - accuracy: 0.8471\n",
      "Epoch 494/500\n",
      "21702/21702 [==============================] - 0s 23us/step - loss: 0.2577 - accuracy: 0.8598\n",
      "Epoch 495/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2530 - accuracy: 0.8699\n",
      "Epoch 496/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3369 - accuracy: 0.8396\n",
      "Epoch 497/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3489 - accuracy: 0.8229\n",
      "Epoch 498/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.2893 - accuracy: 0.8531\n",
      "Epoch 499/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3154 - accuracy: 0.8363\n",
      "Epoch 500/500\n",
      "21702/21702 [==============================] - 0s 22us/step - loss: 0.3193 - accuracy: 0.8282\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fac98524150>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator = KerasClassifier(build_fn=breed_model, epochs=500, batch_size=50, verbose=1)\n",
    "estimator.fit(X_train_breed,pd.get_dummies(pd.DataFrame(y_train_breed).astype(str)).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "34088/34088 [==============================] - 1s 30us/step - loss: 10.4990 - accuracy: 0.2599\n",
      "Epoch 2/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 1.7193 - accuracy: 0.2574\n",
      "Epoch 3/500\n",
      "34088/34088 [==============================] - 1s 23us/step - loss: 1.4935 - accuracy: 0.2758\n",
      "Epoch 4/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 1.4212 - accuracy: 0.2789\n",
      "Epoch 5/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 1.3893 - accuracy: 0.2980\n",
      "Epoch 6/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 1.3648 - accuracy: 0.3155\n",
      "Epoch 7/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 1.3502 - accuracy: 0.3269\n",
      "Epoch 8/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 1.3324 - accuracy: 0.3480\n",
      "Epoch 9/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 1.3184 - accuracy: 0.3703\n",
      "Epoch 10/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 1.2347 - accuracy: 0.4489\n",
      "Epoch 11/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 1.0519 - accuracy: 0.5556\n",
      "Epoch 12/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.9382 - accuracy: 0.5984\n",
      "Epoch 13/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.8904 - accuracy: 0.6265\n",
      "Epoch 14/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.8362 - accuracy: 0.6608\n",
      "Epoch 15/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.8097 - accuracy: 0.6721\n",
      "Epoch 16/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.7732 - accuracy: 0.6860\n",
      "Epoch 17/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.7578 - accuracy: 0.6929\n",
      "Epoch 18/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.7460 - accuracy: 0.7017\n",
      "Epoch 19/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.7364 - accuracy: 0.7095\n",
      "Epoch 20/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.7281 - accuracy: 0.7142\n",
      "Epoch 21/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.7342 - accuracy: 0.7142\n",
      "Epoch 22/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.7011 - accuracy: 0.7280\n",
      "Epoch 23/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6912 - accuracy: 0.7342\n",
      "Epoch 24/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6989 - accuracy: 0.7313\n",
      "Epoch 25/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6816 - accuracy: 0.7409\n",
      "Epoch 26/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.6868 - accuracy: 0.7398\n",
      "Epoch 27/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.6759 - accuracy: 0.7455\n",
      "Epoch 28/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.6752 - accuracy: 0.7452\n",
      "Epoch 29/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6953 - accuracy: 0.7386\n",
      "Epoch 30/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6699 - accuracy: 0.7468\n",
      "Epoch 31/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6461 - accuracy: 0.7588\n",
      "Epoch 32/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6555 - accuracy: 0.7557\n",
      "Epoch 33/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6471 - accuracy: 0.7599\n",
      "Epoch 34/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6340 - accuracy: 0.7654\n",
      "Epoch 35/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6572 - accuracy: 0.7552\n",
      "Epoch 36/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6274 - accuracy: 0.7668\n",
      "Epoch 37/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6623 - accuracy: 0.7520\n",
      "Epoch 38/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6637 - accuracy: 0.7510\n",
      "Epoch 39/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6271 - accuracy: 0.7689\n",
      "Epoch 40/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.6308 - accuracy: 0.7633\n",
      "Epoch 41/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6255 - accuracy: 0.7680\n",
      "Epoch 42/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6222 - accuracy: 0.7702\n",
      "Epoch 43/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6181 - accuracy: 0.7746\n",
      "Epoch 44/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6343 - accuracy: 0.7644\n",
      "Epoch 45/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6036 - accuracy: 0.7762\n",
      "Epoch 46/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6103 - accuracy: 0.7743\n",
      "Epoch 47/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6071 - accuracy: 0.7754\n",
      "Epoch 48/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6087 - accuracy: 0.7751\n",
      "Epoch 49/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5982 - accuracy: 0.7775\n",
      "Epoch 50/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5984 - accuracy: 0.7782\n",
      "Epoch 51/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6005 - accuracy: 0.7768\n",
      "Epoch 52/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6208 - accuracy: 0.7693\n",
      "Epoch 53/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6069 - accuracy: 0.7728\n",
      "Epoch 54/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5857 - accuracy: 0.7814\n",
      "Epoch 55/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6102 - accuracy: 0.7736\n",
      "Epoch 56/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.6013 - accuracy: 0.7789\n",
      "Epoch 57/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5838 - accuracy: 0.7831\n",
      "Epoch 58/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5983 - accuracy: 0.7773\n",
      "Epoch 59/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6010 - accuracy: 0.7770\n",
      "Epoch 60/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5962 - accuracy: 0.7764\n",
      "Epoch 61/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5913 - accuracy: 0.7808\n",
      "Epoch 62/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6092 - accuracy: 0.7754\n",
      "Epoch 63/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5908 - accuracy: 0.7815\n",
      "Epoch 64/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5941 - accuracy: 0.7793\n",
      "Epoch 65/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5892 - accuracy: 0.7817\n",
      "Epoch 66/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5858 - accuracy: 0.7808\n",
      "Epoch 67/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5724 - accuracy: 0.7880\n",
      "Epoch 68/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5901 - accuracy: 0.7811\n",
      "Epoch 69/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5888 - accuracy: 0.7807\n",
      "Epoch 70/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5901 - accuracy: 0.7807\n",
      "Epoch 71/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6528 - accuracy: 0.7487\n",
      "Epoch 72/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6179 - accuracy: 0.7667\n",
      "Epoch 73/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6203 - accuracy: 0.7635\n",
      "Epoch 74/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6107 - accuracy: 0.7685\n",
      "Epoch 75/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6138 - accuracy: 0.7652\n",
      "Epoch 76/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6032 - accuracy: 0.7682\n",
      "Epoch 77/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6078 - accuracy: 0.7667\n",
      "Epoch 78/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6026 - accuracy: 0.7694\n",
      "Epoch 79/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6119 - accuracy: 0.7679\n",
      "Epoch 80/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6046 - accuracy: 0.7699\n",
      "Epoch 81/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.6024 - accuracy: 0.7700\n",
      "Epoch 82/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6121 - accuracy: 0.7669\n",
      "Epoch 83/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5998 - accuracy: 0.7749\n",
      "Epoch 84/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5971 - accuracy: 0.7709\n",
      "Epoch 85/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6218 - accuracy: 0.7652\n",
      "Epoch 86/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5970 - accuracy: 0.7768\n",
      "Epoch 87/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5848 - accuracy: 0.7784\n",
      "Epoch 88/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5949 - accuracy: 0.7765\n",
      "Epoch 89/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5885 - accuracy: 0.7778\n",
      "Epoch 90/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5879 - accuracy: 0.7809\n",
      "Epoch 91/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5775 - accuracy: 0.7873\n",
      "Epoch 92/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5992 - accuracy: 0.7753\n",
      "Epoch 93/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5750 - accuracy: 0.7866\n",
      "Epoch 94/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6162 - accuracy: 0.7717\n",
      "Epoch 95/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.6019 - accuracy: 0.7755\n",
      "Epoch 96/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5816 - accuracy: 0.7813\n",
      "Epoch 97/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5831 - accuracy: 0.7817\n",
      "Epoch 98/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5605 - accuracy: 0.7910\n",
      "Epoch 99/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5753 - accuracy: 0.7857\n",
      "Epoch 100/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5726 - accuracy: 0.7888\n",
      "Epoch 101/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.6141 - accuracy: 0.7693\n",
      "Epoch 102/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5811 - accuracy: 0.7846\n",
      "Epoch 103/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5829 - accuracy: 0.7818\n",
      "Epoch 104/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5614 - accuracy: 0.7897\n",
      "Epoch 105/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5632 - accuracy: 0.7900\n",
      "Epoch 106/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5586 - accuracy: 0.7908\n",
      "Epoch 107/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5750 - accuracy: 0.7811\n",
      "Epoch 108/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5530 - accuracy: 0.7929\n",
      "Epoch 109/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5765 - accuracy: 0.7842\n",
      "Epoch 110/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5696 - accuracy: 0.7848\n",
      "Epoch 111/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5594 - accuracy: 0.7902\n",
      "Epoch 112/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5827 - accuracy: 0.7825\n",
      "Epoch 113/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5753 - accuracy: 0.7835\n",
      "Epoch 114/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5628 - accuracy: 0.7876\n",
      "Epoch 115/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5762 - accuracy: 0.7819\n",
      "Epoch 116/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5661 - accuracy: 0.7874\n",
      "Epoch 117/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5736 - accuracy: 0.7846\n",
      "Epoch 118/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5542 - accuracy: 0.7927\n",
      "Epoch 119/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5742 - accuracy: 0.7838\n",
      "Epoch 120/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5550 - accuracy: 0.7922\n",
      "Epoch 121/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5553 - accuracy: 0.7927\n",
      "Epoch 122/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5678 - accuracy: 0.7887\n",
      "Epoch 123/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5639 - accuracy: 0.7886\n",
      "Epoch 124/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5622 - accuracy: 0.7885\n",
      "Epoch 125/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5623 - accuracy: 0.7896\n",
      "Epoch 126/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5433 - accuracy: 0.7954\n",
      "Epoch 127/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5758 - accuracy: 0.7818\n",
      "Epoch 128/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5759 - accuracy: 0.7878\n",
      "Epoch 129/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5673 - accuracy: 0.7897\n",
      "Epoch 130/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5503 - accuracy: 0.7954\n",
      "Epoch 131/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5593 - accuracy: 0.7901\n",
      "Epoch 132/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5540 - accuracy: 0.7935\n",
      "Epoch 133/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5600 - accuracy: 0.7890\n",
      "Epoch 134/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5691 - accuracy: 0.7895\n",
      "Epoch 135/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5648 - accuracy: 0.7878\n",
      "Epoch 136/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5613 - accuracy: 0.7869\n",
      "Epoch 137/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5464 - accuracy: 0.7944\n",
      "Epoch 138/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5533 - accuracy: 0.7923\n",
      "Epoch 139/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5436 - accuracy: 0.7970\n",
      "Epoch 140/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5482 - accuracy: 0.7948\n",
      "Epoch 141/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5642 - accuracy: 0.7880\n",
      "Epoch 142/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5630 - accuracy: 0.7920\n",
      "Epoch 143/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5470 - accuracy: 0.7971\n",
      "Epoch 144/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5505 - accuracy: 0.7955\n",
      "Epoch 145/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5713 - accuracy: 0.7848\n",
      "Epoch 146/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5516 - accuracy: 0.7922\n",
      "Epoch 147/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5681 - accuracy: 0.7876\n",
      "Epoch 148/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5571 - accuracy: 0.7929\n",
      "Epoch 149/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5623 - accuracy: 0.7877\n",
      "Epoch 150/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5547 - accuracy: 0.7920\n",
      "Epoch 151/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5548 - accuracy: 0.7944\n",
      "Epoch 152/500\n",
      "34088/34088 [==============================] - 1s 27us/step - loss: 0.5482 - accuracy: 0.7960\n",
      "Epoch 153/500\n",
      "34088/34088 [==============================] - 1s 25us/step - loss: 0.5507 - accuracy: 0.7938\n",
      "Epoch 154/500\n",
      "34088/34088 [==============================] - 1s 25us/step - loss: 0.5529 - accuracy: 0.7920\n",
      "Epoch 155/500\n",
      "34088/34088 [==============================] - 1s 24us/step - loss: 0.5536 - accuracy: 0.7944 0s - loss: 0.5518 - accura\n",
      "Epoch 156/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5710 - accuracy: 0.7860\n",
      "Epoch 157/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5491 - accuracy: 0.7911\n",
      "Epoch 158/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5558 - accuracy: 0.7936\n",
      "Epoch 159/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5661 - accuracy: 0.7893\n",
      "Epoch 160/500\n",
      "34088/34088 [==============================] - 1s 25us/step - loss: 0.5492 - accuracy: 0.7928\n",
      "Epoch 161/500\n",
      "34088/34088 [==============================] - 1s 26us/step - loss: 0.5931 - accuracy: 0.7731\n",
      "Epoch 162/500\n",
      "34088/34088 [==============================] - 1s 26us/step - loss: 0.5977 - accuracy: 0.7707\n",
      "Epoch 163/500\n",
      "34088/34088 [==============================] - 1s 27us/step - loss: 0.5914 - accuracy: 0.7711\n",
      "Epoch 164/500\n",
      "34088/34088 [==============================] - 1s 25us/step - loss: 0.5893 - accuracy: 0.7739\n",
      "Epoch 165/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5849 - accuracy: 0.7770\n",
      "Epoch 166/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5670 - accuracy: 0.7866\n",
      "Epoch 167/500\n",
      "34088/34088 [==============================] - 1s 25us/step - loss: 0.5523 - accuracy: 0.7899\n",
      "Epoch 168/500\n",
      "34088/34088 [==============================] - 1s 25us/step - loss: 0.5521 - accuracy: 0.7923\n",
      "Epoch 169/500\n",
      "34088/34088 [==============================] - 1s 25us/step - loss: 0.5907 - accuracy: 0.7723\n",
      "Epoch 170/500\n",
      "34088/34088 [==============================] - 1s 26us/step - loss: 0.5866 - accuracy: 0.7747\n",
      "Epoch 171/500\n",
      "34088/34088 [==============================] - 1s 24us/step - loss: 0.5801 - accuracy: 0.7743\n",
      "Epoch 172/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5765 - accuracy: 0.7761\n",
      "Epoch 173/500\n",
      "34088/34088 [==============================] - 1s 23us/step - loss: 0.6039 - accuracy: 0.7624\n",
      "Epoch 174/500\n",
      "34088/34088 [==============================] - 1s 26us/step - loss: 0.5952 - accuracy: 0.7653\n",
      "Epoch 175/500\n",
      "34088/34088 [==============================] - 1s 25us/step - loss: 0.5882 - accuracy: 0.7695\n",
      "Epoch 176/500\n",
      "34088/34088 [==============================] - 1s 24us/step - loss: 0.6130 - accuracy: 0.7581\n",
      "Epoch 177/500\n",
      "34088/34088 [==============================] - 1s 28us/step - loss: 0.5800 - accuracy: 0.7738\n",
      "Epoch 178/500\n",
      "34088/34088 [==============================] - 1s 26us/step - loss: 0.5820 - accuracy: 0.7732\n",
      "Epoch 179/500\n",
      "34088/34088 [==============================] - 1s 24us/step - loss: 0.5845 - accuracy: 0.7690\n",
      "Epoch 180/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5771 - accuracy: 0.7731\n",
      "Epoch 181/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5928 - accuracy: 0.7699\n",
      "Epoch 182/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5704 - accuracy: 0.7798\n",
      "Epoch 183/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5791 - accuracy: 0.7756\n",
      "Epoch 184/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5673 - accuracy: 0.7824\n",
      "Epoch 185/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5552 - accuracy: 0.7882\n",
      "Epoch 186/500\n",
      "34088/34088 [==============================] - 1s 25us/step - loss: 0.5866 - accuracy: 0.7791\n",
      "Epoch 187/500\n",
      "34088/34088 [==============================] - 1s 23us/step - loss: 0.5492 - accuracy: 0.7927\n",
      "Epoch 188/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5795 - accuracy: 0.7826\n",
      "Epoch 189/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5602 - accuracy: 0.7929\n",
      "Epoch 190/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5520 - accuracy: 0.7960\n",
      "Epoch 191/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5318 - accuracy: 0.8021\n",
      "Epoch 192/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5573 - accuracy: 0.7934\n",
      "Epoch 193/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5445 - accuracy: 0.7969\n",
      "Epoch 194/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5789 - accuracy: 0.7854 0s - loss: 0.5743 - accuracy - ETA: 0s - loss: 0.5789 - accuracy\n",
      "Epoch 195/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5539 - accuracy: 0.7917\n",
      "Epoch 196/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5274 - accuracy: 0.8035\n",
      "Epoch 197/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5545 - accuracy: 0.7972\n",
      "Epoch 198/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5354 - accuracy: 0.7997\n",
      "Epoch 199/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5512 - accuracy: 0.7943\n",
      "Epoch 200/500\n",
      "34088/34088 [==============================] - 1s 23us/step - loss: 0.5920 - accuracy: 0.7765\n",
      "Epoch 201/500\n",
      "34088/34088 [==============================] - 1s 23us/step - loss: 0.5682 - accuracy: 0.7868\n",
      "Epoch 202/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5364 - accuracy: 0.8002\n",
      "Epoch 203/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5370 - accuracy: 0.8015\n",
      "Epoch 204/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5709 - accuracy: 0.7874\n",
      "Epoch 205/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5441 - accuracy: 0.7958\n",
      "Epoch 206/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5395 - accuracy: 0.7972\n",
      "Epoch 207/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5369 - accuracy: 0.7971\n",
      "Epoch 208/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5515 - accuracy: 0.7961\n",
      "Epoch 209/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5280 - accuracy: 0.8029\n",
      "Epoch 210/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5664 - accuracy: 0.7894\n",
      "Epoch 211/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5384 - accuracy: 0.7998\n",
      "Epoch 212/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5440 - accuracy: 0.7982\n",
      "Epoch 213/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5295 - accuracy: 0.8002\n",
      "Epoch 214/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5449 - accuracy: 0.7984\n",
      "Epoch 215/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5361 - accuracy: 0.7988\n",
      "Epoch 216/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5632 - accuracy: 0.7892\n",
      "Epoch 217/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5656 - accuracy: 0.7887\n",
      "Epoch 218/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5619 - accuracy: 0.7932\n",
      "Epoch 219/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5567 - accuracy: 0.7961\n",
      "Epoch 220/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5457 - accuracy: 0.7976\n",
      "Epoch 221/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5537 - accuracy: 0.7947\n",
      "Epoch 222/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5438 - accuracy: 0.7967\n",
      "Epoch 223/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5310 - accuracy: 0.8022\n",
      "Epoch 224/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5542 - accuracy: 0.7924\n",
      "Epoch 225/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5504 - accuracy: 0.7941\n",
      "Epoch 226/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5385 - accuracy: 0.7989\n",
      "Epoch 227/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5439 - accuracy: 0.7967\n",
      "Epoch 228/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5298 - accuracy: 0.8055\n",
      "Epoch 229/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5224 - accuracy: 0.8067\n",
      "Epoch 230/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5399 - accuracy: 0.7988\n",
      "Epoch 231/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5465 - accuracy: 0.7939\n",
      "Epoch 232/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5396 - accuracy: 0.7978\n",
      "Epoch 233/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5432 - accuracy: 0.7961\n",
      "Epoch 234/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5296 - accuracy: 0.8039\n",
      "Epoch 235/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5346 - accuracy: 0.8020\n",
      "Epoch 236/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5332 - accuracy: 0.7987\n",
      "Epoch 237/500\n",
      "34088/34088 [==============================] - 1s 23us/step - loss: 0.5230 - accuracy: 0.8057\n",
      "Epoch 238/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5442 - accuracy: 0.7965\n",
      "Epoch 239/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5325 - accuracy: 0.8001\n",
      "Epoch 240/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5299 - accuracy: 0.8016\n",
      "Epoch 241/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5338 - accuracy: 0.8006\n",
      "Epoch 242/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5359 - accuracy: 0.7997\n",
      "Epoch 243/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5663 - accuracy: 0.7907\n",
      "Epoch 244/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5277 - accuracy: 0.8024\n",
      "Epoch 245/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5571 - accuracy: 0.7884\n",
      "Epoch 246/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5438 - accuracy: 0.7932\n",
      "Epoch 247/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5784 - accuracy: 0.7773\n",
      "Epoch 248/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5638 - accuracy: 0.7774\n",
      "Epoch 249/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5731 - accuracy: 0.7721\n",
      "Epoch 250/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5736 - accuracy: 0.7739\n",
      "Epoch 251/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5871 - accuracy: 0.7668\n",
      "Epoch 252/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5873 - accuracy: 0.7678\n",
      "Epoch 253/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5634 - accuracy: 0.7783\n",
      "Epoch 254/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5608 - accuracy: 0.7758\n",
      "Epoch 255/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5584 - accuracy: 0.7783\n",
      "Epoch 256/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5679 - accuracy: 0.7768\n",
      "Epoch 257/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5625 - accuracy: 0.7773\n",
      "Epoch 258/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5657 - accuracy: 0.7789\n",
      "Epoch 259/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5755 - accuracy: 0.7734\n",
      "Epoch 260/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.6007 - accuracy: 0.7631\n",
      "Epoch 261/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.6172 - accuracy: 0.7421\n",
      "Epoch 262/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5515 - accuracy: 0.7815\n",
      "Epoch 263/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5495 - accuracy: 0.7863\n",
      "Epoch 264/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5665 - accuracy: 0.7799\n",
      "Epoch 265/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5657 - accuracy: 0.7792\n",
      "Epoch 266/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5434 - accuracy: 0.7881\n",
      "Epoch 267/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5642 - accuracy: 0.7838\n",
      "Epoch 268/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5527 - accuracy: 0.7854\n",
      "Epoch 269/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5507 - accuracy: 0.7856\n",
      "Epoch 270/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5668 - accuracy: 0.7809\n",
      "Epoch 271/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5521 - accuracy: 0.7878\n",
      "Epoch 272/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5572 - accuracy: 0.7876\n",
      "Epoch 273/500\n",
      "34088/34088 [==============================] - 1s 26us/step - loss: 0.5500 - accuracy: 0.7927\n",
      "Epoch 274/500\n",
      "34088/34088 [==============================] - 1s 25us/step - loss: 0.5956 - accuracy: 0.7683\n",
      "Epoch 275/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5472 - accuracy: 0.7926\n",
      "Epoch 276/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5506 - accuracy: 0.7846\n",
      "Epoch 277/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5588 - accuracy: 0.7824\n",
      "Epoch 278/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5659 - accuracy: 0.7761\n",
      "Epoch 279/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5600 - accuracy: 0.7795\n",
      "Epoch 280/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5807 - accuracy: 0.7734\n",
      "Epoch 281/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5557 - accuracy: 0.7813\n",
      "Epoch 282/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5530 - accuracy: 0.7917\n",
      "Epoch 283/500\n",
      "34088/34088 [==============================] - 1s 23us/step - loss: 0.5555 - accuracy: 0.7927\n",
      "Epoch 284/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5291 - accuracy: 0.8050\n",
      "Epoch 285/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5510 - accuracy: 0.7941\n",
      "Epoch 286/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5595 - accuracy: 0.7927\n",
      "Epoch 287/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5235 - accuracy: 0.8061\n",
      "Epoch 288/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5187 - accuracy: 0.8070\n",
      "Epoch 289/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5349 - accuracy: 0.7996\n",
      "Epoch 290/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5351 - accuracy: 0.7976\n",
      "Epoch 291/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5281 - accuracy: 0.8044\n",
      "Epoch 292/500\n",
      "34088/34088 [==============================] - 1s 25us/step - loss: 0.5504 - accuracy: 0.7946\n",
      "Epoch 293/500\n",
      "34088/34088 [==============================] - 1s 23us/step - loss: 0.5298 - accuracy: 0.8056\n",
      "Epoch 294/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5301 - accuracy: 0.8020\n",
      "Epoch 295/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5336 - accuracy: 0.7995\n",
      "Epoch 296/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5414 - accuracy: 0.7977\n",
      "Epoch 297/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5408 - accuracy: 0.7972\n",
      "Epoch 298/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5446 - accuracy: 0.7969\n",
      "Epoch 299/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5358 - accuracy: 0.7981\n",
      "Epoch 300/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5536 - accuracy: 0.7928\n",
      "Epoch 301/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5513 - accuracy: 0.7914\n",
      "Epoch 302/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5440 - accuracy: 0.7975\n",
      "Epoch 303/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5356 - accuracy: 0.8011\n",
      "Epoch 304/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5565 - accuracy: 0.7943\n",
      "Epoch 305/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5478 - accuracy: 0.7977\n",
      "Epoch 306/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5524 - accuracy: 0.7933\n",
      "Epoch 307/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5324 - accuracy: 0.7995\n",
      "Epoch 308/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5339 - accuracy: 0.8012 0s - loss: 0.5334 - accuracy\n",
      "Epoch 309/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5291 - accuracy: 0.8029\n",
      "Epoch 310/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5242 - accuracy: 0.8069\n",
      "Epoch 311/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5508 - accuracy: 0.7944\n",
      "Epoch 312/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5249 - accuracy: 0.8030\n",
      "Epoch 313/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5410 - accuracy: 0.7981\n",
      "Epoch 314/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5204 - accuracy: 0.8060\n",
      "Epoch 315/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5204 - accuracy: 0.8039\n",
      "Epoch 316/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5589 - accuracy: 0.7853\n",
      "Epoch 317/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5451 - accuracy: 0.7859\n",
      "Epoch 318/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5481 - accuracy: 0.7865\n",
      "Epoch 319/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5563 - accuracy: 0.7849\n",
      "Epoch 320/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5517 - accuracy: 0.7823\n",
      "Epoch 321/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5544 - accuracy: 0.7833\n",
      "Epoch 322/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5343 - accuracy: 0.7971\n",
      "Epoch 323/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5385 - accuracy: 0.8016\n",
      "Epoch 324/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5526 - accuracy: 0.7918\n",
      "Epoch 325/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5436 - accuracy: 0.7970\n",
      "Epoch 326/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5367 - accuracy: 0.8012\n",
      "Epoch 327/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5555 - accuracy: 0.7927\n",
      "Epoch 328/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5502 - accuracy: 0.7933\n",
      "Epoch 329/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5277 - accuracy: 0.8000\n",
      "Epoch 330/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5285 - accuracy: 0.8026\n",
      "Epoch 331/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5275 - accuracy: 0.8037\n",
      "Epoch 332/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5320 - accuracy: 0.8022\n",
      "Epoch 333/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5308 - accuracy: 0.7994\n",
      "Epoch 334/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5251 - accuracy: 0.8048\n",
      "Epoch 335/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5128 - accuracy: 0.8092\n",
      "Epoch 336/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5244 - accuracy: 0.8044\n",
      "Epoch 337/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5260 - accuracy: 0.8038\n",
      "Epoch 338/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5510 - accuracy: 0.7964\n",
      "Epoch 339/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5621 - accuracy: 0.7895\n",
      "Epoch 340/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5420 - accuracy: 0.7968\n",
      "Epoch 341/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5304 - accuracy: 0.7975\n",
      "Epoch 342/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5347 - accuracy: 0.7991\n",
      "Epoch 343/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5259 - accuracy: 0.8014\n",
      "Epoch 344/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5593 - accuracy: 0.7851\n",
      "Epoch 345/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5653 - accuracy: 0.7804\n",
      "Epoch 346/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5526 - accuracy: 0.7821\n",
      "Epoch 347/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5525 - accuracy: 0.7831\n",
      "Epoch 348/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5430 - accuracy: 0.7868 0s - loss: 0.5418 - accuracy: 0.78\n",
      "Epoch 349/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5470 - accuracy: 0.7857\n",
      "Epoch 350/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5545 - accuracy: 0.7834\n",
      "Epoch 351/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5344 - accuracy: 0.7981\n",
      "Epoch 352/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5448 - accuracy: 0.7927\n",
      "Epoch 353/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5991 - accuracy: 0.7736\n",
      "Epoch 354/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5396 - accuracy: 0.7967\n",
      "Epoch 355/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5309 - accuracy: 0.8011\n",
      "Epoch 356/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5275 - accuracy: 0.8079\n",
      "Epoch 357/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5158 - accuracy: 0.8082\n",
      "Epoch 358/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5446 - accuracy: 0.7967\n",
      "Epoch 359/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5488 - accuracy: 0.7952\n",
      "Epoch 360/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5385 - accuracy: 0.7965\n",
      "Epoch 361/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5367 - accuracy: 0.7969\n",
      "Epoch 362/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5233 - accuracy: 0.8022\n",
      "Epoch 363/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5514 - accuracy: 0.7907\n",
      "Epoch 364/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5633 - accuracy: 0.7752\n",
      "Epoch 365/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5627 - accuracy: 0.7772\n",
      "Epoch 366/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5450 - accuracy: 0.7926\n",
      "Epoch 367/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5193 - accuracy: 0.8080\n",
      "Epoch 368/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5328 - accuracy: 0.8007\n",
      "Epoch 369/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5389 - accuracy: 0.7986\n",
      "Epoch 370/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5203 - accuracy: 0.8032\n",
      "Epoch 371/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5230 - accuracy: 0.8037\n",
      "Epoch 372/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5276 - accuracy: 0.8030\n",
      "Epoch 373/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5554 - accuracy: 0.7907\n",
      "Epoch 374/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5322 - accuracy: 0.7998 0s - loss: 0.5329 - accu\n",
      "Epoch 375/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5138 - accuracy: 0.8087\n",
      "Epoch 376/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5190 - accuracy: 0.8065\n",
      "Epoch 377/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5314 - accuracy: 0.7980\n",
      "Epoch 378/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5353 - accuracy: 0.8016\n",
      "Epoch 379/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5356 - accuracy: 0.8006\n",
      "Epoch 380/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5517 - accuracy: 0.7935\n",
      "Epoch 381/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5375 - accuracy: 0.7965\n",
      "Epoch 382/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5338 - accuracy: 0.7985\n",
      "Epoch 383/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5272 - accuracy: 0.8020\n",
      "Epoch 384/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5190 - accuracy: 0.8051\n",
      "Epoch 385/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5289 - accuracy: 0.8002\n",
      "Epoch 386/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5213 - accuracy: 0.8034\n",
      "Epoch 387/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5153 - accuracy: 0.8061\n",
      "Epoch 388/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5221 - accuracy: 0.8028\n",
      "Epoch 389/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5154 - accuracy: 0.8075\n",
      "Epoch 390/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5317 - accuracy: 0.8017\n",
      "Epoch 391/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5248 - accuracy: 0.8049\n",
      "Epoch 392/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5148 - accuracy: 0.8091\n",
      "Epoch 393/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5205 - accuracy: 0.8002\n",
      "Epoch 394/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5296 - accuracy: 0.8020\n",
      "Epoch 395/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5312 - accuracy: 0.7989\n",
      "Epoch 396/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5293 - accuracy: 0.8025\n",
      "Epoch 397/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5498 - accuracy: 0.7976\n",
      "Epoch 398/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5355 - accuracy: 0.8002\n",
      "Epoch 399/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5833 - accuracy: 0.7815\n",
      "Epoch 400/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5528 - accuracy: 0.7915\n",
      "Epoch 401/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5391 - accuracy: 0.7992\n",
      "Epoch 402/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5758 - accuracy: 0.7890\n",
      "Epoch 403/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5435 - accuracy: 0.7933\n",
      "Epoch 404/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5508 - accuracy: 0.7921\n",
      "Epoch 405/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5212 - accuracy: 0.8041\n",
      "Epoch 406/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5280 - accuracy: 0.8032\n",
      "Epoch 407/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5434 - accuracy: 0.7969\n",
      "Epoch 408/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5271 - accuracy: 0.8034\n",
      "Epoch 409/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5484 - accuracy: 0.7935\n",
      "Epoch 410/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5240 - accuracy: 0.8049\n",
      "Epoch 411/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5355 - accuracy: 0.8025\n",
      "Epoch 412/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5407 - accuracy: 0.8011\n",
      "Epoch 413/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5474 - accuracy: 0.7954\n",
      "Epoch 414/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5549 - accuracy: 0.7915\n",
      "Epoch 415/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5494 - accuracy: 0.7955\n",
      "Epoch 416/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5352 - accuracy: 0.8008\n",
      "Epoch 417/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5350 - accuracy: 0.7986\n",
      "Epoch 418/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5432 - accuracy: 0.7984\n",
      "Epoch 419/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5305 - accuracy: 0.8004\n",
      "Epoch 420/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5295 - accuracy: 0.8047\n",
      "Epoch 421/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5188 - accuracy: 0.8070\n",
      "Epoch 422/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5354 - accuracy: 0.7997\n",
      "Epoch 423/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5432 - accuracy: 0.7957\n",
      "Epoch 424/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5029 - accuracy: 0.8121\n",
      "Epoch 425/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5167 - accuracy: 0.8070\n",
      "Epoch 426/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5289 - accuracy: 0.8041\n",
      "Epoch 427/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5372 - accuracy: 0.7937\n",
      "Epoch 428/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5750 - accuracy: 0.7726\n",
      "Epoch 429/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5814 - accuracy: 0.7708\n",
      "Epoch 430/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5550 - accuracy: 0.7832\n",
      "Epoch 431/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5181 - accuracy: 0.8059\n",
      "Epoch 432/500\n",
      "34088/34088 [==============================] - 1s 23us/step - loss: 0.5267 - accuracy: 0.8046\n",
      "Epoch 433/500\n",
      "34088/34088 [==============================] - 1s 25us/step - loss: 0.5153 - accuracy: 0.8089\n",
      "Epoch 434/500\n",
      "34088/34088 [==============================] - 1s 26us/step - loss: 0.5190 - accuracy: 0.8055\n",
      "Epoch 435/500\n",
      "34088/34088 [==============================] - 1s 27us/step - loss: 0.5532 - accuracy: 0.7860\n",
      "Epoch 436/500\n",
      "34088/34088 [==============================] - 1s 25us/step - loss: 0.5630 - accuracy: 0.7812 0s - loss: 0.5605 - accuracy: 0.78\n",
      "Epoch 437/500\n",
      "34088/34088 [==============================] - 1s 23us/step - loss: 0.5543 - accuracy: 0.7793\n",
      "Epoch 438/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5431 - accuracy: 0.7847\n",
      "Epoch 439/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5477 - accuracy: 0.7824\n",
      "Epoch 440/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5544 - accuracy: 0.7817\n",
      "Epoch 441/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5540 - accuracy: 0.7796\n",
      "Epoch 442/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5712 - accuracy: 0.7777\n",
      "Epoch 443/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5436 - accuracy: 0.7862\n",
      "Epoch 444/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5702 - accuracy: 0.7747\n",
      "Epoch 445/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5351 - accuracy: 0.7888\n",
      "Epoch 446/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5318 - accuracy: 0.7967\n",
      "Epoch 447/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5370 - accuracy: 0.7973\n",
      "Epoch 448/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5513 - accuracy: 0.7920\n",
      "Epoch 449/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5392 - accuracy: 0.7969\n",
      "Epoch 450/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5407 - accuracy: 0.7970\n",
      "Epoch 451/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.6149 - accuracy: 0.7741\n",
      "Epoch 452/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5506 - accuracy: 0.7929\n",
      "Epoch 453/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5377 - accuracy: 0.7969\n",
      "Epoch 454/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5232 - accuracy: 0.8038\n",
      "Epoch 455/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5386 - accuracy: 0.7963\n",
      "Epoch 456/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5354 - accuracy: 0.7976\n",
      "Epoch 457/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5219 - accuracy: 0.8026\n",
      "Epoch 458/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5258 - accuracy: 0.8029\n",
      "Epoch 459/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5146 - accuracy: 0.8059\n",
      "Epoch 460/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5388 - accuracy: 0.7902\n",
      "Epoch 461/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5477 - accuracy: 0.7809\n",
      "Epoch 462/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5518 - accuracy: 0.7836\n",
      "Epoch 463/500\n",
      "34088/34088 [==============================] - 1s 24us/step - loss: 0.5424 - accuracy: 0.7869\n",
      "Epoch 464/500\n",
      "34088/34088 [==============================] - 1s 23us/step - loss: 0.5516 - accuracy: 0.7834\n",
      "Epoch 465/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5506 - accuracy: 0.7823\n",
      "Epoch 466/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5624 - accuracy: 0.7804\n",
      "Epoch 467/500\n",
      "34088/34088 [==============================] - 1s 23us/step - loss: 0.5546 - accuracy: 0.7782\n",
      "Epoch 468/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5536 - accuracy: 0.7826\n",
      "Epoch 469/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5204 - accuracy: 0.8045\n",
      "Epoch 470/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5276 - accuracy: 0.8018\n",
      "Epoch 471/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5549 - accuracy: 0.7927\n",
      "Epoch 472/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5425 - accuracy: 0.7953\n",
      "Epoch 473/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5377 - accuracy: 0.7951\n",
      "Epoch 474/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5271 - accuracy: 0.8032\n",
      "Epoch 475/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5345 - accuracy: 0.7985\n",
      "Epoch 476/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5364 - accuracy: 0.7989\n",
      "Epoch 477/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5369 - accuracy: 0.8012\n",
      "Epoch 478/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5283 - accuracy: 0.8037\n",
      "Epoch 479/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5478 - accuracy: 0.7964\n",
      "Epoch 480/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5504 - accuracy: 0.7937\n",
      "Epoch 481/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5704 - accuracy: 0.7869\n",
      "Epoch 482/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5498 - accuracy: 0.7908\n",
      "Epoch 483/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5408 - accuracy: 0.7936\n",
      "Epoch 484/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5224 - accuracy: 0.8022\n",
      "Epoch 485/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5235 - accuracy: 0.8041\n",
      "Epoch 486/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5259 - accuracy: 0.8030\n",
      "Epoch 487/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5342 - accuracy: 0.8007\n",
      "Epoch 488/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5410 - accuracy: 0.7991\n",
      "Epoch 489/500\n",
      "34088/34088 [==============================] - 1s 23us/step - loss: 0.5668 - accuracy: 0.7848\n",
      "Epoch 490/500\n",
      "34088/34088 [==============================] - 1s 24us/step - loss: 0.5407 - accuracy: 0.7927\n",
      "Epoch 491/500\n",
      "34088/34088 [==============================] - 1s 23us/step - loss: 0.5238 - accuracy: 0.8015\n",
      "Epoch 492/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5258 - accuracy: 0.8012\n",
      "Epoch 493/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5220 - accuracy: 0.8027\n",
      "Epoch 494/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5433 - accuracy: 0.7953\n",
      "Epoch 495/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5259 - accuracy: 0.8044\n",
      "Epoch 496/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5354 - accuracy: 0.8010\n",
      "Epoch 497/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5434 - accuracy: 0.8002\n",
      "Epoch 498/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5309 - accuracy: 0.7997\n",
      "Epoch 499/500\n",
      "34088/34088 [==============================] - 1s 22us/step - loss: 0.5146 - accuracy: 0.8079\n",
      "Epoch 500/500\n",
      "34088/34088 [==============================] - 1s 21us/step - loss: 0.5247 - accuracy: 0.8025\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x7fac985c98d0>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "estimator_pet = KerasClassifier(build_fn=pet_model, epochs=500, batch_size=50, verbose=1)\n",
    "estimator_pet.fit(X_train_pet,pd.get_dummies(pd.DataFrame(y_train_pet).astype(str)).values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3767/3767 [==============================] - 0s 18us/step\n"
     ]
    }
   ],
   "source": [
    "breed_preds = estimator.predict(X_test_breed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3767/3767 [==============================] - 0s 18us/step\n"
     ]
    }
   ],
   "source": [
    "pet_preds = estimator_pet.predict(X_test_pet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1761,    4,    1],\n",
       "       [ 429, 1282,    0],\n",
       "       [   0,    0,  290]])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_breed, breed_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[   5,    0,    1,    3,    0],\n",
       "       [  16, 1127,  278,   22,    0],\n",
       "       [  61,   95, 1919,   24,    0],\n",
       "       [   0,    0,    0,    0,    0],\n",
       "       [  47,    5,   24,  140,    0]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test_pet, pet_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8072/8072 [==============================] - 0s 9us/step\n",
      "8072/8072 [==============================] - 0s 7us/step\n"
     ]
    }
   ],
   "source": [
    "breed_preds = estimator.predict(main_test)\n",
    "pet_preds = estimator_pet.predict(main_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['pet_id'] = soln_df.pet_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['breed_category'] = breed_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission['pet_category'] = pet_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.breed_category = submission.breed_category.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pet_id</th>\n",
       "      <th>breed_category</th>\n",
       "      <th>pet_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ANSL_75005</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ANSL_76663</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ANSL_58259</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ANSL_67171</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ANSL_72871</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8067</th>\n",
       "      <td>ANSL_66809</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8068</th>\n",
       "      <td>ANSL_59041</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8069</th>\n",
       "      <td>ANSL_60034</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8070</th>\n",
       "      <td>ANSL_58066</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8071</th>\n",
       "      <td>ANSL_69436</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8072 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          pet_id  breed_category  pet_category\n",
       "0     ANSL_75005               1             2\n",
       "1     ANSL_76663               0             1\n",
       "2     ANSL_58259               0             2\n",
       "3     ANSL_67171               0             2\n",
       "4     ANSL_72871               0             2\n",
       "...          ...             ...           ...\n",
       "8067  ANSL_66809               0             3\n",
       "8068  ANSL_59041               1             2\n",
       "8069  ANSL_60034               1             2\n",
       "8070  ANSL_58066               2             0\n",
       "8071  ANSL_69436               1             2\n",
       "\n",
       "[8072 rows x 3 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv('submission_6.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
